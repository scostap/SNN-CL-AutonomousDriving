{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76f488a-1bc1-4f3d-b39a-f7bbc4fca35a",
   "metadata": {},
   "source": [
    "##  0. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012877d6-6a54-4c10-8ffe-95702f265c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, glob, gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8a0c2-f879-4152-9fc1-acf63015b48a",
   "metadata": {},
   "source": [
    "## 1. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8a0eca-deba-435f-be06-0803f255ce90",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/scosta/TFM/CL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_colab, base_dir\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Detect environment and set up paths\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m is_colab, base_dir \u001b[38;5;241m=\u001b[39m \u001b[43msetup_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36msetup_environment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     is_colab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Change to the base directory\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Print the current working directory\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent working directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/scosta/TFM/CL'"
     ]
    }
   ],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"Setup paths and detect if running on Google Colab.\"\"\"\n",
    "    try:\n",
    "        # Check if running on Google Colab\n",
    "        from google.colab import drive\n",
    "\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "        base_dir = '/content/TFM/SNN/CL'\n",
    "        os.makedirs(f\"{base_dir}CL\", exist_ok=True)\n",
    "\n",
    "        is_colab = True\n",
    "    except ImportError:\n",
    "        # Fallback for local environment\n",
    "        base_dir = '/home/scosta/TFM/SNN/CL'\n",
    "        is_colab = False\n",
    "\n",
    "    # Change to the base directory\n",
    "    os.chdir(base_dir)\n",
    "\n",
    "    # Print the current working directory\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    return is_colab, base_dir\n",
    "\n",
    "\n",
    "# Detect environment and set up paths\n",
    "is_colab, base_dir = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1447041c-c818-4bcf-8f67-410a36b05b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/scosta/TFM/SNN/work/') # deleteme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352d688-9608-4259-9be1-38faedcd7e19",
   "metadata": {},
   "source": [
    "##  2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02361574-06f2-47eb-abae-6177fceb5512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Metrics logs\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob('./**/metrics.csv', recursive=True)\n",
    "\n",
    "# Load files\n",
    "data_frames = []\n",
    "for file_path in file_paths:\n",
    "    # Extract the full directory name\n",
    "    full_dir = file_path.split('/')[1]\n",
    "    \n",
    "    # Extract the version number\n",
    "    version = file_path.split('/')[2].split('_')[1]  # Assumes \"version_X\" structure in the path\n",
    "    \n",
    "    # Extract the task name\n",
    "    task_name_match = re.search(r'SNN_CL_(.*?)_rate', full_dir)\n",
    "    task_name = task_name_match.group(1) if task_name_match else None\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add columns for the task name, directory, and version\n",
    "    df['Task'] = task_name\n",
    "    df['Directory'] = full_dir\n",
    "    df['Version'] = version\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    data_frames.append(df)\n",
    "    \n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Reshape the DataFrame to proper structure\n",
    "metrics_columns = ['co2_emissions', 'ewc_loss',\n",
    "       'test_loss/dataloader_idx_0', 'test_loss/dataloader_idx_1',\n",
    "       'train_loss', 'val_loss/dataloader_idx_0', 'val_loss/dataloader_idx_1', 'val_loss/dataloader_idx_2']  # Adjust these to match your actual column names\n",
    "id_columns = [col for col in final_df.columns if col not in metrics_columns]  # Keep all other columns as identifiers\n",
    "\n",
    "melted_df = pd.melt(\n",
    "    final_df,\n",
    "    id_vars=id_columns,  # Columns to keep as identifiers\n",
    "    value_vars=metrics_columns,  # Columns to unpivot\n",
    "    var_name='Metric',  # New column name for metrics\n",
    "    value_name='Value'  # New column name for values\n",
    ")\n",
    "\n",
    "# Remove rows with NaN in the 'Value' column if any\n",
    "melted_df = melted_df.dropna(subset=['Value'])\n",
    "\n",
    "# Sort the DataFrame by 'Task', 'Metric', and 'Version'\n",
    "melted_df = melted_df.sort_values(by=['Task', 'Metric', 'Version'], ascending=[True, True, True])\n",
    "\n",
    "# Rename fields to match numbering\n",
    "melted_df['Metric'] = melted_df['Metric'].str.replace('dataloader_idx_', 'task_')\n",
    "melted_df[melted_df['Task'] == 'task2_cumulative'] = melted_df[melted_df['Task'] == 'task2_cumulative'].replace('val_loss/task_2', 'val_loss/task_1&2')\n",
    "melted_df['Metric'] = melted_df['Metric'].replace('val_loss/task_1', 'val_loss/task_2')\n",
    "melted_df['Metric'] = melted_df['Metric'].replace('val_loss/task_0', 'val_loss/task_1')\n",
    "melted_df['Metric'] = melted_df['Metric'].replace('test_loss/task_1', 'test_loss/task_2')\n",
    "melted_df['Metric'] = melted_df['Metric'].replace('test_loss/task_0', 'test_loss/task_1')\n",
    "\n",
    "\n",
    "# Calculate cobined val_loss and test_loss for tracks 1 and 2 (in all but cumulative model)\n",
    "# Exclude specific tasks from grouping\n",
    "filtered_df = melted_df[(~melted_df['Task'].isin(['task2_cummulative'])) & (melted_df['Metric'].isin(['val_loss/task_1', 'val_loss/task_2']))]\n",
    "filtered2_df = melted_df[melted_df['Metric'].isin(['test_loss/task_1', 'test_loss/task_2'])]\n",
    "\n",
    "# Grouping by relevant columns and calculating mean value\n",
    "grouped = (\n",
    "    filtered_df.groupby(['epoch', 'step', 'Task', 'Directory', 'Version'], as_index=False)\n",
    "    .agg({'Value': 'mean'})\n",
    ")\n",
    "\n",
    "grouped2 = (\n",
    "    filtered2_df.groupby(['epoch', 'step', 'Task', 'Directory', 'Version'], as_index=False)\n",
    "    .agg({'Value': 'mean'})\n",
    ")\n",
    "\n",
    "# Add a new column for the combined metric name\n",
    "grouped['Metric'] = 'val_loss/task_1&2'\n",
    "grouped2['Metric'] = 'test_loss/task_1&2'\n",
    "\n",
    "# Combine the grouped rows back with the original DataFrame\n",
    "result = pd.concat([melted_df, grouped, grouped2], ignore_index=True)\n",
    "\n",
    "# Sort the final DataFrame for clarity\n",
    "df = result.sort_values(by=['epoch', 'step', 'Task', 'Version']).reset_index(drop=True)\n",
    "\n",
    "# Cleanup at the end\n",
    "del data_frames, final_df, melted_df, filtered_df, filtered2_df, grouped, grouped2, result\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0061a7a2-aed4-489e-8120-69754b66e5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Time and CO2 emission logs from CodeCarbon logs\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob('./**/emissions*.csv', recursive=True)\n",
    "\n",
    "# Step 3: Process each file\n",
    "data_frames = []\n",
    "for file_path in file_paths:\n",
    "    # Extract the full directory name\n",
    "    full_dir = file_path.split('/')[1]\n",
    "    \n",
    "    # Extract the version number\n",
    "    version = file_path.split('/')[2].split('_')[1]\n",
    "    \n",
    "    # Extract the task name\n",
    "    task_name_match = re.search(r'SNN_CL_(.*?)_rate', full_dir)\n",
    "    task_name = task_name_match.group(1) if task_name_match else None\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    other_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add columns for the task name, directory, and version\n",
    "    other_df['Task'] = task_name\n",
    "    other_df['Directory'] = full_dir\n",
    "    other_df['Version'] = version\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    data_frames.append(other_df)\n",
    "    \n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Rename emissions column\n",
    "final_df.rename(columns={'emissions': 'Value'}, inplace=True)\n",
    "\n",
    "# Round CO2 emissions values\n",
    "df.loc[df['Metric'] == 'co2_emissions', 'Value'] = df.loc[df['Metric'] == 'co2_emissions', 'Value'].round(6)\n",
    "final_df['Value'] = final_df['Value'].round(6)\n",
    "\n",
    "# Left join based on Task, Version and CO2_value\n",
    "merged = pd.merge(\n",
    "    df[df['Metric'] == 'co2_emissions'].sort_values(by=['Task','Version', 'step'], ascending=True),\n",
    "    final_df.sort_values(by=['Task','Version','Value'], ascending=True)[['Task', 'Version','Value', 'timestamp', 'duration']], \n",
    "    on=['Task','Version','Value'], \n",
    "    how='left' \n",
    ")\n",
    "\n",
    "# Unpivot duration\n",
    "id_columns = ['epoch', 'step', 'Task', 'Directory', 'Version',\n",
    "       'timestamp']\n",
    "metrics_columns = ['duration']\n",
    "\n",
    "melted_df = pd.melt(\n",
    "    merged.drop('Value', axis=1),\n",
    "    id_vars=id_columns, \n",
    "    value_vars=metrics_columns,  \n",
    "    var_name='Metric',  \n",
    "    value_name='Value' \n",
    ")\n",
    "\n",
    "# Remove rows with NaN in the 'Value' column\n",
    "melted_df = melted_df.dropna(subset=['Value'])\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat([df, melted_df], ignore_index=True)\n",
    "\n",
    "# Cleanup at the end\n",
    "del data_frames, final_df, melted_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e389613-f7a7-4b7c-8613-374b9d3a2b5d",
   "metadata": {},
   "source": [
    "## 3. Filter data by epoch of  best performance on task 2 (best models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73938df6-d4f5-447d-bc39-660448bb1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>Task</th>\n",
       "      <th>Directory</th>\n",
       "      <th>Version</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>task1</td>\n",
       "      <td>SNN_CL_task1_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>ewc_loss</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1028</td>\n",
       "      <td>task1</td>\n",
       "      <td>SNN_CL_task1_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>1077</td>\n",
       "      <td>task1</td>\n",
       "      <td>SNN_CL_task1_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>co2_emissions</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1077</td>\n",
       "      <td>task1</td>\n",
       "      <td>SNN_CL_task1_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>ewc_loss</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1077</td>\n",
       "      <td>task1</td>\n",
       "      <td>SNN_CL_task1_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>58</td>\n",
       "      <td>4542</td>\n",
       "      <td>task2_naive</td>\n",
       "      <td>SNN_CL_task2_naive_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>duration</td>\n",
       "      <td>3378.969228</td>\n",
       "      <td>2024-12-19T02:53:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>55</td>\n",
       "      <td>4311</td>\n",
       "      <td>task2_naive</td>\n",
       "      <td>SNN_CL_task2_naive_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>duration</td>\n",
       "      <td>3075.423814</td>\n",
       "      <td>2024-12-19T03:46:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>59</td>\n",
       "      <td>4619</td>\n",
       "      <td>task2_naive</td>\n",
       "      <td>SNN_CL_task2_naive_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>duration</td>\n",
       "      <td>3522.931513</td>\n",
       "      <td>2024-12-19T04:52:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>57</td>\n",
       "      <td>4465</td>\n",
       "      <td>task2_naive</td>\n",
       "      <td>SNN_CL_task2_naive_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>duration</td>\n",
       "      <td>3324.366687</td>\n",
       "      <td>2024-12-19T05:48:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>56</td>\n",
       "      <td>4388</td>\n",
       "      <td>task2_naive</td>\n",
       "      <td>SNN_CL_task2_naive_rate_numsteps_25_gain_0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>duration</td>\n",
       "      <td>3233.769511</td>\n",
       "      <td>2024-12-19T06:46:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  step         Task                                     Directory  \\\n",
       "0       13  1028        task1        SNN_CL_task1_rate_numsteps_25_gain_0.5   \n",
       "1       13  1028        task1        SNN_CL_task1_rate_numsteps_25_gain_0.5   \n",
       "2       13  1077        task1        SNN_CL_task1_rate_numsteps_25_gain_0.5   \n",
       "3       13  1077        task1        SNN_CL_task1_rate_numsteps_25_gain_0.5   \n",
       "4       13  1077        task1        SNN_CL_task1_rate_numsteps_25_gain_0.5   \n",
       "..     ...   ...          ...                                           ...   \n",
       "685     58  4542  task2_naive  SNN_CL_task2_naive_rate_numsteps_25_gain_0.5   \n",
       "686     55  4311  task2_naive  SNN_CL_task2_naive_rate_numsteps_25_gain_0.5   \n",
       "687     59  4619  task2_naive  SNN_CL_task2_naive_rate_numsteps_25_gain_0.5   \n",
       "688     57  4465  task2_naive  SNN_CL_task2_naive_rate_numsteps_25_gain_0.5   \n",
       "689     56  4388  task2_naive  SNN_CL_task2_naive_rate_numsteps_25_gain_0.5   \n",
       "\n",
       "    Version         Metric        Value            timestamp  \n",
       "0         2       ewc_loss     0.000000                  NaN  \n",
       "1         2     train_loss     0.035925                  NaN  \n",
       "2         2  co2_emissions     0.005240                  NaN  \n",
       "3         2       ewc_loss     0.000000                  NaN  \n",
       "4         2     train_loss     0.030908                  NaN  \n",
       "..      ...            ...          ...                  ...  \n",
       "685       0       duration  3378.969228  2024-12-19T02:53:16  \n",
       "686       1       duration  3075.423814  2024-12-19T03:46:42  \n",
       "687       2       duration  3522.931513  2024-12-19T04:52:54  \n",
       "688       3       duration  3324.366687  2024-12-19T05:48:44  \n",
       "689       4       duration  3233.769511  2024-12-19T06:46:38  \n",
       "\n",
       "[690 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for 'val_loss' metric on task 2\n",
    "val_loss_data = df[df['Metric'] == 'val_loss/task_2']\n",
    "\n",
    "# Find the row with the minimum val_loss for each Task and Version\n",
    "min_val_loss = val_loss_data.loc[val_loss_data.groupby(['Task', 'Version'])['Value'].idxmin()]\n",
    "\n",
    "# Select rows from df1 where columns match df2\n",
    "best_models_df= df.merge(min_val_loss, on=['epoch', 'Task', 'Version'], suffixes=('','_y'))\n",
    "best_models_df.drop(columns=['step_y', 'Directory_y', 'Metric_y',\n",
    "       'Value_y', 'timestamp_y'], inplace=True)\n",
    "\n",
    "best_models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b74df-cefc-4437-9ce8-604bd1403f70",
   "metadata": {},
   "source": [
    "## 4. Summary results statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42df3fff-518a-4edd-9024-8f421407f3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">co2_emissions</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ewc_loss</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_loss</th>\n",
       "      <th colspan=\"2\" halign=\"left\">val_loss/task_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">val_loss/task_1&amp;2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">val_loss/task_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>task2_cumulative</th>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>6310.994483</td>\n",
       "      <td>713.694311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.025976</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.039356</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_Rep0.15</th>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>3838.647218</td>\n",
       "      <td>355.410141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>0.001924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_Rep0.25</th>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>4424.266393</td>\n",
       "      <td>235.187490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024294</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.041576</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.051881</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_Rep0.2</th>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>4157.368060</td>\n",
       "      <td>234.869927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.031520</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.041808</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.052096</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_Rep0.1</th>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>3688.671941</td>\n",
       "      <td>164.085562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032131</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_Rep0.05</th>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>3251.545412</td>\n",
       "      <td>237.438751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029112</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.043609</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_ewc_1.0e+12</th>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>3725.731311</td>\n",
       "      <td>115.919998</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.076071</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.039217</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.058804</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_ewc_1.0e+11</th>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>3569.433721</td>\n",
       "      <td>107.965652</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.063371</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.060978</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.067159</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_ewc_5.0e+10</th>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>3534.323601</td>\n",
       "      <td>114.675649</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.053552</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.063190</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_ewc_1.0e+10</th>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>3395.317305</td>\n",
       "      <td>133.475173</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.047948</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.059108</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_naive</th>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>3307.092151</td>\n",
       "      <td>166.656669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.077842</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>0.065612</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.053382</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2_ewc_1.0e+09</th>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>3426.438285</td>\n",
       "      <td>40.377275</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.066047</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task1</th>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>2498.717659</td>\n",
       "      <td>611.880511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.122456</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.214570</td>\n",
       "      <td>0.023536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric            co2_emissions               duration              ewc_loss  \\\n",
       "                           mean       std         mean         std      mean   \n",
       "Task                                                                           \n",
       "task2_cumulative       0.022668  0.002544  6310.994483  713.694311  0.000000   \n",
       "task2_Rep0.15          0.013789  0.001278  3838.647218  355.410141  0.000000   \n",
       "task2_Rep0.25          0.015855  0.000868  4424.266393  235.187490  0.000000   \n",
       "task2_Rep0.2           0.014919  0.000888  4157.368060  234.869927  0.000000   \n",
       "task2_Rep0.1           0.013210  0.000607  3688.671941  164.085562  0.000000   \n",
       "task2_Rep0.05          0.011762  0.000879  3251.545412  237.438751  0.000000   \n",
       "task2_ewc_1.0e+12      0.013346  0.000449  3725.731311  115.919998  0.000257   \n",
       "task2_ewc_1.0e+11      0.012821  0.000356  3569.433721  107.965652  0.000235   \n",
       "task2_ewc_5.0e+10      0.012735  0.000414  3534.323601  114.675649  0.000226   \n",
       "task2_ewc_1.0e+10      0.012286  0.000471  3395.317305  133.475173  0.000228   \n",
       "task2_naive            0.011939  0.000628  3307.092151  166.656669  0.000000   \n",
       "task2_ewc_1.0e+09      0.012434  0.000180  3426.438285   40.377275  0.000219   \n",
       "task1                  0.009035  0.002234  2498.717659  611.880511  0.000000   \n",
       "\n",
       "Metric                      train_loss           val_loss/task_1            \\\n",
       "                        std       mean       std            mean       std   \n",
       "Task                                                                         \n",
       "task2_cumulative   0.000000   0.026283  0.005607        0.025976  0.000461   \n",
       "task2_Rep0.15      0.000000   0.035539  0.006639        0.031115  0.001906   \n",
       "task2_Rep0.25      0.000000   0.024294  0.003289        0.031271  0.001388   \n",
       "task2_Rep0.2       0.000000   0.028580  0.004143        0.031520  0.000698   \n",
       "task2_Rep0.1       0.000000   0.032131  0.006112        0.033536  0.001333   \n",
       "task2_Rep0.05      0.000000   0.029112  0.004563        0.036481  0.001685   \n",
       "task2_ewc_1.0e+12  0.000050   0.076071  0.012667        0.039217  0.005619   \n",
       "task2_ewc_1.0e+11  0.000023   0.063371  0.012759        0.054798  0.005450   \n",
       "task2_ewc_5.0e+10  0.000015   0.053552  0.007815        0.060501  0.006389   \n",
       "task2_ewc_1.0e+10  0.000025   0.047948  0.007012        0.066805  0.006766   \n",
       "task2_naive        0.000000   0.029709  0.002829        0.077842  0.008649   \n",
       "task2_ewc_1.0e+09  0.000019   0.045931  0.006379        0.074306  0.009335   \n",
       "task1              0.000000   0.025206  0.007935        0.030343  0.006052   \n",
       "\n",
       "Metric            val_loss/task_1&2           val_loss/task_2            \n",
       "                               mean       std            mean       std  \n",
       "Task                                                                     \n",
       "task2_cumulative           0.039356  0.000351        0.052744  0.000700  \n",
       "task2_Rep0.15              0.041190  0.001289        0.051265  0.001924  \n",
       "task2_Rep0.25              0.041576  0.000983        0.051881  0.001284  \n",
       "task2_Rep0.2               0.041808  0.001190        0.052096  0.002306  \n",
       "task2_Rep0.1               0.042525  0.000820        0.051515  0.000450  \n",
       "task2_Rep0.05              0.043609  0.001134        0.050736  0.000964  \n",
       "task2_ewc_1.0e+12          0.058804  0.002058        0.078392  0.004138  \n",
       "task2_ewc_1.0e+11          0.060978  0.002314        0.067159  0.002202  \n",
       "task2_ewc_5.0e+10          0.061845  0.002965        0.063190  0.000958  \n",
       "task2_ewc_1.0e+10          0.062956  0.003489        0.059108  0.001363  \n",
       "task2_naive                0.065612  0.004158        0.053382  0.001262  \n",
       "task2_ewc_1.0e+09          0.066047  0.004714        0.057787  0.001018  \n",
       "task1                      0.122456  0.014555        0.214570  0.023536  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove ewc_loss if not needed\n",
    "best_models_df = best_models_df[best_models_df['Metric'] != 'ewc_loss']\n",
    "# Group by Task and Metric and calculate the mean and standard deviation of the 'Value' column\n",
    "grouped_stats = best_models_df.groupby(['Task', 'Metric'])['Value'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Set 'Metric' as the main index and 'mean' and 'std' as subindexes\n",
    "grouped_stats.set_index(['Task', 'Metric'], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "grouped_stats = grouped_stats.stack().unstack('Task').transpose().sort_values(by=[('val_loss/task_1&2', 'mean')], ascending=True)\n",
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32265e4a-b036-42b2-bb3e-38d96644eb70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
